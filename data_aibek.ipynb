{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfdc145b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка библиотек\n",
    "import pandas as pd\n",
    "import sqlalchemy as sa\n",
    "from sqlalchemy import text\n",
    "import pickle\n",
    "import os\n",
    "import joblib\n",
    "from lime import lime_tabular\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from datetime import datetime as dt\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "\n",
    "wells_df = pd.read_excel('tags_2025.xlsx', sheet_name='WELLS')\n",
    "\n",
    "wells_df.columns = wells_df.columns.str.strip()\n",
    "\n",
    "wells_df['wellid'] = wells_df['wellid'].astype(str)\n",
    "\n",
    "target_wellid = \"2\" \n",
    "\n",
    "row = wells_df.loc[wells_df['wellid'] == target_wellid]\n",
    "wellid = target_wellid\n",
    "\n",
    "if not row.empty:\n",
    "    unit = row['unit'].values[0]\n",
    "    site = row['site'].values[0]\n",
    "    wellpad = row['wellpad'].values[0]\n",
    "    well = str(row['well'].values[0])\n",
    "    mid = str(row['mid'].values[0])\n",
    "\n",
    "    print(f\"Цех: {unit}, Участок: {site}, Сборный пункт: {wellpad}, скважина: {well}, MID: {mid}, wellid: {wellid}\" )\n",
    "else:\n",
    "    print(f\"WellID {target_wellid} not found in the data.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "14744413-492f-469c-8fa9-25fc7f4fcc68",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlalchemy as sa\n",
    "\n",
    "engine = sa.create_engine(\n",
    "    f\"postgresql://sarah_user:allineedisosh@SRV-IMMO0101UZ/SARAH\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4e3fd103-3e39-45e3-801a-0fb3bca113aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Получение данных с БД\n",
    "wells_features_query = text(\"\"\"\n",
    "    SELECT * FROM wells.well_features\n",
    "    WHERE wellid = 2 AND mid = :mid AND datetime >= '2021-12-01' AND datetime <= '2025-03-07'\n",
    "    ORDER BY datetime ASC\n",
    "\"\"\")\n",
    "\n",
    "well_general_query = text(\"\"\"\n",
    "    SELECT * FROM wells.general_features\n",
    "    WHERE mid = :mid AND datetime >= '2021-12-01' AND datetime <= '2025-03-07'\n",
    "    ORDER BY datetime ASC\n",
    "\"\"\")\n",
    "\n",
    "measurements_query = text(\"\"\"\n",
    "    SELECT * FROM wells.measurements\n",
    "    WHERE well = :well AND datetime >= '2021-12-01' AND datetime <= '2025-03-07'\n",
    "    ORDER BY datetime ASC\n",
    "\"\"\")\n",
    "\n",
    "with engine.connect() as conn:\n",
    "    wells_features = pd.read_sql(wells_features_query, conn, params={'well': well, 'mid': mid})\n",
    "    well_general = pd.read_sql(well_general_query, conn, params={'mid': mid})\n",
    "    measurements = pd.read_sql(measurements_query, conn, params={'well': well, 'mid': mid})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34373649-8b50-4bc8-a238-dfc6c28846eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовка формата данных \n",
    "def convert_to_float(df):\n",
    "    for col in df.columns:\n",
    "        if col != 'datetime':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "77d2d23f-bd73-4769-83be-b9795525fb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Подготовка формата данных \n",
    "wells_features = convert_to_float(wells_features)\n",
    "well_general = convert_to_float(well_general)\n",
    "measurements = convert_to_float(measurements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "45c106e5-cf00-46dc-b088-ed2be5db9583",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Объединяем данные в один датафррейм \n",
    "import pandas as pd\n",
    "\n",
    "wells_features['datetime'] = pd.to_datetime(wells_features['datetime'])\n",
    "\n",
    "well_general['datetime'] = pd.to_datetime(well_general['datetime'])\n",
    "\n",
    "combined_1 = pd.merge(wells_features, well_general, on=['datetime', 'mid'], how='inner')\n",
    "combined_2 = pd.merge(combined_1, measurements, on=['datetime', 'mid', 'wellid'], how='inner')\n",
    "df = combined_2\n",
    "\n",
    "def convert_to_float(df):\n",
    "    for col in df.columns:\n",
    "        if col != 'datetime':\n",
    "            df[col] = pd.to_numeric(df[col], errors='coerce')\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08107c1e-7623-491d-83d3-7743721d180a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Удаляем столбцы с большим числом пропусков\n",
    "threshold_df = len(df) * 0.5\n",
    "df = df.dropna(axis=1, thresh=threshold_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1711ded",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация дополнительных признаков\n",
    "df['delta_t'] = 0\n",
    "for index, row in df.iterrows():\n",
    "    if 't1' in df.columns:\n",
    "        df.loc[index, 'delta_t'] = row['t1'] - row['t9']\n",
    "    elif 't2' in df.columns:\n",
    "        df.loc[index, 'delta_t'] = row['t2'] - row['t9']\n",
    "    elif 't3' in df.columns:\n",
    "        df.loc[index, 'delta_t'] = row['t3'] - row['t9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c1454f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Генерация дополнительных признаков\n",
    "df['delta_p'] = 0\n",
    "for index, row in df.iterrows():\n",
    "    if 'p1' in df.columns:\n",
    "        df.loc[index, 'delta_p'] = row['p1'] - row['p3']\n",
    "    elif 'p2' in df.columns:\n",
    "        df.loc[index, 'delta_p'] = row['p2'] - row['p3']\n",
    "    elif 'p3' in df.columns:\n",
    "        df.loc[index, 'delta_p'] = row['p3'] - row['p4']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d7930d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Оставляем только таргеты\n",
    "df = df.dropna(subset=['q_g'])\n",
    "df.describe().T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9772ce9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим  графики для чистки данных\n",
    "import plotly.express as px\n",
    "\n",
    "def show_histogram(data, title):\n",
    "    fig = px.histogram(data, title=title, template='plotly_white')\n",
    "    fig.show()\n",
    "\n",
    "for column in df.columns:\n",
    "    show_histogram(df[column], f'Гистограмма для {column}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f905639c-4ac3-4cd3-81e7-7b1e83db2af7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Чистка данных\n",
    "thresholds = {\n",
    "    'd1': (0, 1000),\n",
    "    'h1': (0, 100),\n",
    "    'p1': (3, 15),\n",
    "    'p2': (3, 15),\n",
    "    'p3': (3, 15),\n",
    "    'p4': (3, 12),\n",
    "    'p5': (0, 120),\n",
    "    'p6': (0, 120),\n",
    "    'p7': (3, 6),\n",
    "    't1': (0, 75),\n",
    "    't2': (0, 100),\n",
    "    't3': (0, 75),\n",
    "    't4': (0, 40),\n",
    "    't7': (10, 75),\n",
    "    't8': (0, 50),\n",
    "    't9': (0, 75),\n",
    "    'v1': (0, 100)\n",
    "}\n",
    "\n",
    "\n",
    "for column, (min_val, max_val) in thresholds.items():\n",
    "    if column in df.columns:\n",
    "        df = df[(df[column] > min_val) & (df[column] < max_val)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5c56a9b1-a2b4-4f9c-81bd-c7825ec53145",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding для определения временного коэффициента\n",
    "df['datetime'] = pd.to_datetime(df['datetime'])\n",
    "df['hour'] = df['datetime'].dt.hour\n",
    "df['hour'] = df['hour'].apply(lambda x: 24 if x == 0 else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fecaf9da-61db-427d-a7e9-eaf1eb874205",
   "metadata": {},
   "outputs": [],
   "source": [
    "# One Hot Encoding для определения временного коэффициента\n",
    "one_hot = pd.get_dummies(df['hour'], prefix='h', prefix_sep='_')\n",
    "\n",
    "df = pd.concat([df, one_hot], axis=1)\n",
    "for col in one_hot.columns:\n",
    "    df[col] = df[col].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "15487831-70df-4657-9650-14655bdd2fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB-scan для чистки результатов замеров скважин от аномалий\n",
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import numpy as np\n",
    "import datetime\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import warnings\n",
    "from sklearn.cluster import DBSCAN\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "WELLID = wellid\n",
    "WELL = well\n",
    "MID = mid\n",
    "\n",
    "GRAY = '#798897'\n",
    "RED = '#d2233c'\n",
    "GREEN = '#00873f'\n",
    "BLUE = '#5d58ec'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "2167e4e8-a67b-4fb7-812a-7fd5d8c41b1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB-scan для чистки результатов замеров скважин от аномалий\n",
    "df.index = df['datetime'] \n",
    "df['DDT'] = df.index\n",
    "df['DDT'] = (df.DDT.diff().dt.total_seconds() / 50).abs()\n",
    "df['DDT'] = (df.DDT>360).astype(int).cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5944af3b-58fd-4809-9403-fcbfb4ee6579",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB-scan для чистки результатов замеров скважин от аномалий\n",
    "def get_preclear(indata):\n",
    "    pipe = Pipeline([('scaler', StandardScaler()), ('dbscan', DBSCAN(eps=1.05, min_samples=25))])\n",
    "    X = indata[['q_g']]\n",
    "    X['cluster'] = pipe.fit_predict(X)\n",
    "    indata['HEALTH'] = X.cluster.apply(lambda x: True if x == 0 else False)\n",
    "    indata['GOOD_Q_G'] = indata.apply(lambda x: x.q_g if x.HEALTH == True  else np.nan, axis=1)\n",
    "    indata['BAD_Q_G'] = indata.apply(lambda x: x.q_g if x.HEALTH == False  else np.nan, axis=1)\n",
    "    return indata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "309d8de9-9975-4e0f-829d-280ca0e06efa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB-scan для чистки результатов замеров скважин от аномалий\n",
    "summary = pd.DataFrame()\n",
    "for num in df.DDT.unique():\n",
    "    if len(df[df.DDT == num]) > 0:\n",
    "        summary = pd.concat([summary, get_preclear(df[df.DDT == num])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9bb755d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Строим график эффективности чистки результатов замеров скважин от аномалий\n",
    "import plotly.express as px\n",
    "\n",
    "def show_scatter_plot(data):\n",
    "    fig = px.scatter(data, template='plotly_white', \n",
    "                     color_discrete_sequence=[GREEN, RED, BLUE, GRAY], height=555, text='DDT')\n",
    "    fig.show()\n",
    "\n",
    "show_scatter_plot(summary[['GOOD_Q_G', 'BAD_Q_G', 'DDT']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "840d3523-5975-45e3-9283-78397522d4e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB-scan для чистки результатов замеров скважин от аномалий\n",
    "summary = summary.dropna(subset='GOOD_Q_G')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2afc1376",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DB-scan для чистки результатов замеров скважин от аномалий\n",
    "df = summary\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "87b5afe1-763e-493d-a928-dfdbd71fd015",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка датафрейма для обучения модели\n",
    "rw = df\n",
    "df = df[df.HEALTH == True]\n",
    "df = df.drop(['DDT', 'HEALTH', 'GOOD_Q_G', 'BAD_Q_G', 'datetime','wellid', 'well','hour','q_w','q_c','verification_x','verification_y'], axis=1)\n",
    "df= df.dropna()\n",
    "X = df.drop(['q_g'], axis=1)\n",
    "y = df[['q_g']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "981dafc6-2494-40ea-9165-81b6933bc55a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Подготовка датафрейма для обучения модели, размер обучаемой и тестовой выборки и т.д.  \n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.00001, random_state=42, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "681e1267",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Обучение моделей на данных, построение графиков на естовых данных, расчет метрик качества моделей  \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.linear_model import HuberRegressor, Ridge, LinearRegression, Lasso, BayesianRidge, ElasticNet\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "from catboost import CatBoostRegressor\n",
    "import pickle\n",
    "\n",
    "def create_pipeline(model, degree):\n",
    "    return Pipeline([\n",
    "        ('poly', PolynomialFeatures(degree=degree, include_bias=False)),\n",
    "        ('model', model)\n",
    "    ])\n",
    "\n",
    "models = {\n",
    "    'Huber': HuberRegressor(),\n",
    "    'Ridge': Ridge(alpha=1.0),\n",
    "    'Linear': LinearRegression(),\n",
    "    'Lasso': Lasso(alpha=0.7),\n",
    "    'BayesianRidge': BayesianRidge(),\n",
    "    'ElasticNet': ElasticNet(alpha=1.0, l1_ratio=0.5),\n",
    "    'CatBoost': CatBoostRegressor(verbose=0)\n",
    "}\n",
    "\n",
    "pipelines = {}\n",
    "for name, model in models.items():\n",
    "    for degree in [1, 2]:\n",
    "        pipeline_name = f\"{name}_degree_{degree}\"\n",
    "        pipelines[pipeline_name] = create_pipeline(model, degree)\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, pipeline in pipelines.items():\n",
    "    pipeline.fit(X_train, y_train)\n",
    "    y_pred = pipeline.predict(X_test)\n",
    "\n",
    "    mae = mean_absolute_error(y_test, y_pred)  # Changed from mean_squared_error to mean_absolute_error\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "    results[name] = {'MAE': mae, 'R2': r2}\n",
    "\n",
    "    with open(f'{name}.pkl', 'wb') as file:\n",
    "        pickle.dump(pipeline, file)\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.plot(range(len(y_test)), y_test, label='Actual', marker='o')\n",
    "    plt.plot(range(len(y_pred)), y_pred, label='Predicted', linestyle='--')\n",
    "\n",
    "    plt.title(f'Comparison for {name}')\n",
    "    plt.xlabel('Sample Index')\n",
    "    plt.ylabel('Value')\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n",
    "\n",
    "for name, metrics in results.items():\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"  MAE: {metrics['MAE']:.4f}\")\n",
    "    print(f\"  R2: {metrics['R2']:.4f}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4413244b-2a3d-47a0-b936-00826a0e6d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Сохранение обученной модели \n",
    "with open('Lasso_degree_2.pkl', 'rb') as file:\n",
    "    loaded_lasso_degree_2 = pickle.load(file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
